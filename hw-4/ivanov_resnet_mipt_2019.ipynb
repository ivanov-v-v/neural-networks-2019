{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "True\n",
      "4 GeForce GTX 1080 Ti\n",
      "0\n",
      "<torch.cuda.device object at 0x7f16b4ae6dd8>\n",
      "CudaVersion :  9.0.176\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count(), torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(\"CudaVersion : \",torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)\n",
    "\n",
    "### Для запуска без GPU раскомментировать и закоментировать код выше\n",
    "# DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тут папки с пробелами НЕ надо заключать в \"\"\n",
    "DATA_PATH  = '/home/vv.ivanov/neural-networks-2019/hw-4/data/'\n",
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mean = np.mean(\n",
    "    [\n",
    "        item[0].numpy() \n",
    "        for item in CifarDataset(\n",
    "            DATA_PATH + train_path, \n",
    "            transform=transforms.ToTensor()\n",
    "        )\n",
    "    ], \n",
    "    axis=(0,2,3)\n",
    ")\n",
    "np_std = np.std(\n",
    "    [item[0].numpy() \n",
    "     for item in CifarDataset(\n",
    "         DATA_PATH + train_path, \n",
    "         transform=transforms.ToTensor()\n",
    "     )], \n",
    "    axis=(0,2,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "])\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = CifarDataset(DATA_PATH + train_path, transform=cifar_transform_norm)\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset(DATA_PATH + test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  a_epochs=164,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_acc = []\n",
    "    net = a_net.to(a_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    prev_epoch_time = start_time\n",
    "    for epoch in range(a_epochs):  # loop over the dataset multiple times\n",
    "        #optimizer = torch.optim.SGD(a_net.parameters(), lr=0.1 ** (epoch // 30 + 1) / 5, weight_decay=0.0001, momentum=0.9)\n",
    "        if epoch == 41:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/4, weight_decay=0.0001, momentum=0.9)\n",
    "        elif epoch == 82:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/10, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 123:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/100, weight_decay=0.0001, momentum=0.9)\n",
    "        elif epoch == 150:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/200, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        for item in dataloader_train_norm:\n",
    "\n",
    "            epoch_iters += 1\n",
    "\n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #             prediction2classes(outputs)\n",
    "\n",
    "    #             print(labels.cpu())\n",
    "    #             print(prediction2classes(outputs))\n",
    "            epoch_accuracy += accuracy_score(labels.cpu(), prediction2classes(outputs))\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "\n",
    "        print(\"Epoch \", epoch, round(train_acc[-1], 4))\n",
    "        cur_epoch_time = time.time()\n",
    "        print('Epoch time : ', cur_epoch_time - prev_epoch_time )\n",
    "        prev_epoch_time = cur_epoch_time\n",
    "\n",
    "        my_solution = make_solution(a_net, DEVICE)\n",
    "        file_name = DATA_PATH + 'my_solution.csv'\n",
    "\n",
    "        with open(file_name, 'w') as fout:\n",
    "            print('Id', 'Prediction', sep=',', file=fout)\n",
    "            for i, prediction in enumerate(my_solution):\n",
    "                  print(i, prediction, sep=',', file=fout)\n",
    "\n",
    "    print('Finished Training')\n",
    "    print(\"Total time : \", (time.time()-start_time))\n",
    "\n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.legend()\n",
    "    #     plt.grid()\n",
    "    plt.grid(c='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(a_in_planes, a_out_planes, a_stride=1):\n",
    "    \"\"\"\n",
    "    Основной строительный блок конволюций для ResNet\n",
    "    Включает в себя padding=1 - чтобы размерность сохранялась после его применения\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(a_in_planes, \n",
    "                     a_out_planes,  \n",
    "                     stride=a_stride,\n",
    "                     kernel_size=3, \n",
    "                     padding=1, \n",
    "                     bias=False).cuda()\n",
    "\n",
    "def conv1x1(a_in_planes, a_out_planes):\n",
    "    \"\"\"\n",
    "    Ещё один основной строительный блок конволюций для ResNet\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,\n",
    "                     kernel_size=1, bias=False)\n",
    "\n",
    "def x_downsample(a_in_planes, a_out_planes, stride):\n",
    "    # я немного изменил сигнатуру, т.к. нам не всегда нужно\n",
    "    # уменьшать размерность картинки (в отличие от обычного ResNet)\n",
    "    return nn.Conv2d(a_in_planes, \n",
    "                     a_out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_planes, a_out_planes, stride=1):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.a_in_planes = a_in_planes\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=a_in_planes)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=a_out_planes)\n",
    "        \n",
    "        self.conv1 = conv3x3(a_in_planes, a_out_planes)\n",
    "        self.conv2 = conv3x3(a_out_planes, a_out_planes, stride)\n",
    "        \n",
    "        self.downsample = x_downsample(a_in_planes, a_out_planes, stride)\n",
    "        self.dropout = nn.Dropout(p=0.3) # чтобы не переобучалось\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # в статье порядок блоков был не такой, как у нас\n",
    "        # поэтому я его изменил\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += self.downsample(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class CifarWideResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarWideResNet, self).__init__()\n",
    "        # архитектура из статьи про WideResNet\n",
    "        self.expansion_factor = 4\n",
    "        self.in_planes = 16\n",
    "        # я посмотрел в статье, какая конфигурация сети пробивает baseline, и взял чуть побольше\n",
    "        self.plane_lst = np.hstack(([16], np.array([16, 32, 64, 128]) * self.expansion_factor))\n",
    "        # страйды такие, т.к. на каждом блоке, кроме первого, нужно сжимать картинку в два раза\n",
    "        self.stride_lst = np.hstack(([1], np.full(self.plane_lst.size - 1, 2)))\n",
    "        # контролирует число resnet-блоков в каждом \"слое\"\n",
    "        self.blocks_per_layer = 3\n",
    "\n",
    "        # всего здесь будет self.plane_lst.size слоёв,\n",
    "        # в каждом из которых self.blocks_per_layes resnet-блоков\n",
    "        self.features = self._assemble_resnet_layers()\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(self.plane_lst[-1])\n",
    "        self.relu = nn.ReLU(inplace=True) \n",
    "        self.global_avg_pooling = nn.AvgPool2d(kernel_size=8)\n",
    "        self.fc = nn.Linear(self.plane_lst[-1], 100)\n",
    "    \n",
    "    def _assemble_resnet_layers(self):\n",
    "        \"\"\"\n",
    "        Собирает слои из resnet-блоков\n",
    "        \"\"\"\n",
    "        blocks = OrderedDict([(\"conv_0\", conv3x3(3, self.plane_lst[0]))])\n",
    "        for i in range(1, self.plane_lst.size):\n",
    "            blocks[f\"res_{i}_0\"] = CifarResidualBlock(self.plane_lst[i-1], \n",
    "                                                     self.plane_lst[i], \n",
    "                                                     stride=self.stride_lst[i-1])\n",
    "            for j in range(1, self.blocks_per_layer):\n",
    "                blocks[f\"res_{i}_{j}\"] = CifarResidualBlock(self.plane_lst[i], \n",
    "                                                            self.plane_lst[i])\n",
    "        return nn.Sequential(blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.global_avg_pooling(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 0.0651\n",
      "Epoch time :  50.29225397109985\n",
      "Epoch  1 0.1408\n",
      "Epoch time :  53.80798840522766\n",
      "Epoch  2 0.1981\n",
      "Epoch time :  54.217467069625854\n",
      "Epoch  3 0.2483\n",
      "Epoch time :  54.2347891330719\n",
      "Epoch  4 0.2913\n",
      "Epoch time :  54.33428072929382\n",
      "Epoch  5 0.3277\n",
      "Epoch time :  54.23528170585632\n",
      "Epoch  6 0.3568\n",
      "Epoch time :  54.2319540977478\n",
      "Epoch  7 0.3803\n",
      "Epoch time :  54.25842833518982\n",
      "Epoch  8 0.4025\n",
      "Epoch time :  54.56266474723816\n",
      "Epoch  9 0.4246\n",
      "Epoch time :  54.37941336631775\n",
      "Epoch  10 0.4412\n",
      "Epoch time :  54.218852519989014\n",
      "Epoch  11 0.4569\n",
      "Epoch time :  54.3460168838501\n",
      "Epoch  12 0.4727\n",
      "Epoch time :  54.34378981590271\n",
      "Epoch  13 0.4853\n",
      "Epoch time :  54.32023811340332\n",
      "Epoch  14 0.5003\n",
      "Epoch time :  54.16166853904724\n",
      "Epoch  15 0.5125\n",
      "Epoch time :  54.28823399543762\n",
      "Epoch  16 0.52\n",
      "Epoch time :  54.453396797180176\n",
      "Epoch  17 0.5297\n",
      "Epoch time :  54.49353361129761\n",
      "Epoch  18 0.536\n",
      "Epoch time :  54.521279096603394\n",
      "Epoch  19 0.5456\n",
      "Epoch time :  54.427082777023315\n",
      "Epoch  20 0.5556\n",
      "Epoch time :  54.49783754348755\n",
      "Epoch  21 0.5599\n",
      "Epoch time :  54.53049182891846\n",
      "Epoch  22 0.5691\n",
      "Epoch time :  54.488341093063354\n",
      "Epoch  23 0.5779\n",
      "Epoch time :  54.44210982322693\n",
      "Epoch  24 0.5822\n",
      "Epoch time :  54.61752414703369\n",
      "Epoch  25 0.5881\n",
      "Epoch time :  54.585389852523804\n",
      "Epoch  26 0.5923\n",
      "Epoch time :  54.491697549819946\n",
      "Epoch  27 0.5962\n",
      "Epoch time :  54.42423725128174\n",
      "Epoch  28 0.6007\n",
      "Epoch time :  54.18386125564575\n",
      "Epoch  29 0.6085\n",
      "Epoch time :  54.14494609832764\n",
      "Epoch  30 0.6099\n",
      "Epoch time :  54.36102247238159\n",
      "Epoch  31 0.6157\n",
      "Epoch time :  54.32052731513977\n",
      "Epoch  32 0.6167\n",
      "Epoch time :  54.36243510246277\n",
      "Epoch  33 0.6181\n",
      "Epoch time :  54.42113375663757\n",
      "Epoch  34 0.628\n",
      "Epoch time :  54.533995389938354\n",
      "Epoch  35 0.6265\n",
      "Epoch time :  54.57817006111145\n",
      "Epoch  36 0.6286\n",
      "Epoch time :  54.524569272994995\n",
      "Epoch  37 0.6383\n",
      "Epoch time :  54.30198359489441\n",
      "Epoch  38 0.6367\n",
      "Epoch time :  54.39448165893555\n",
      "Epoch  39 0.638\n",
      "Epoch time :  54.598058462142944\n",
      "Epoch  40 0.6467\n",
      "Epoch time :  54.61322498321533\n",
      "Epoch  41 0.7615\n",
      "Epoch time :  54.544952392578125\n",
      "Epoch  42 0.7913\n",
      "Epoch time :  54.510089635849\n",
      "Epoch  43 0.8016\n",
      "Epoch time :  54.50418663024902\n",
      "Epoch  44 0.8082\n",
      "Epoch time :  54.53301453590393\n",
      "Epoch  45 0.8161\n",
      "Epoch time :  54.619664907455444\n",
      "Epoch  46 0.8221\n",
      "Epoch time :  54.56724405288696\n",
      "Epoch  47 0.8279\n",
      "Epoch time :  54.69564247131348\n",
      "Epoch  48 0.8343\n",
      "Epoch time :  54.65320134162903\n",
      "Epoch  49 0.8368\n",
      "Epoch time :  54.59262657165527\n",
      "Epoch  50 0.8431\n",
      "Epoch time :  54.65954256057739\n",
      "Epoch  51 0.8471\n",
      "Epoch time :  54.64603781700134\n",
      "Epoch  52 0.8505\n",
      "Epoch time :  54.63249588012695\n",
      "Epoch  53 0.8553\n",
      "Epoch time :  54.625444173812866\n",
      "Epoch  54 0.8584\n",
      "Epoch time :  54.778908014297485\n",
      "Epoch  55 0.8591\n",
      "Epoch time :  55.03701639175415\n",
      "Epoch  56 0.8637\n",
      "Epoch time :  54.551976442337036\n",
      "Epoch  57 0.8673\n",
      "Epoch time :  54.65240454673767\n",
      "Epoch  58 0.87\n",
      "Epoch time :  54.71254587173462\n",
      "Epoch  59 0.8723\n",
      "Epoch time :  54.78497672080994\n",
      "Epoch  60 0.8761\n",
      "Epoch time :  54.74201440811157\n",
      "Epoch  61 0.8733\n",
      "Epoch time :  54.77318024635315\n",
      "Epoch  62 0.8788\n",
      "Epoch time :  54.498136043548584\n",
      "Epoch  63 0.881\n",
      "Epoch time :  54.605101585388184\n",
      "Epoch  64 0.8833\n",
      "Epoch time :  54.722254276275635\n",
      "Epoch  65 0.8873\n",
      "Epoch time :  54.662840843200684\n",
      "Epoch  66 0.887\n",
      "Epoch time :  54.67358589172363\n",
      "Epoch  67 0.8914\n",
      "Epoch time :  54.722031116485596\n",
      "Epoch  68 0.8924\n",
      "Epoch time :  54.674569606781006\n",
      "Epoch  69 0.893\n",
      "Epoch time :  54.72975492477417\n",
      "Epoch  70 0.8939\n",
      "Epoch time :  54.57503914833069\n",
      "Epoch  71 0.8935\n",
      "Epoch time :  54.684948444366455\n",
      "Epoch  72 0.8949\n",
      "Epoch time :  54.737488985061646\n",
      "Epoch  73 0.8992\n",
      "Epoch time :  54.85959458351135\n",
      "Epoch  74 0.9016\n",
      "Epoch time :  54.667473554611206\n",
      "Epoch  75 0.8997\n",
      "Epoch time :  54.597684383392334\n",
      "Epoch  76 0.9077\n",
      "Epoch time :  54.676490783691406\n",
      "Epoch  77 0.9054\n",
      "Epoch time :  54.66553783416748\n",
      "Epoch  78 0.9035\n",
      "Epoch time :  54.637142181396484\n",
      "Epoch  79 0.9085\n",
      "Epoch time :  54.74774694442749\n",
      "Epoch  80 0.9076\n",
      "Epoch time :  54.68536043167114\n",
      "Epoch  81 0.9116\n",
      "Epoch time :  54.721763610839844\n",
      "Epoch  82 0.9572\n",
      "Epoch time :  54.731863260269165\n",
      "Epoch  83 0.9731\n",
      "Epoch time :  54.61419320106506\n",
      "Epoch  84 0.9766\n",
      "Epoch time :  54.8158483505249\n",
      "Epoch  85 0.9801\n",
      "Epoch time :  54.668734073638916\n",
      "Epoch  86 0.9829\n",
      "Epoch time :  54.74744725227356\n",
      "Epoch  87 0.9827\n",
      "Epoch time :  54.72951889038086\n",
      "Epoch  88 0.9837\n",
      "Epoch time :  54.757442474365234\n",
      "Epoch  89 0.9836\n",
      "Epoch time :  54.75227665901184\n",
      "Epoch  90 0.985\n",
      "Epoch time :  54.636900186538696\n",
      "Epoch  91 0.9845\n",
      "Epoch time :  54.7545645236969\n",
      "Epoch  92 0.9855\n",
      "Epoch time :  54.77013921737671\n",
      "Epoch  93 0.9868\n",
      "Epoch time :  56.29207897186279\n",
      "Epoch  94 0.9874\n",
      "Epoch time :  57.40548491477966\n",
      "Epoch  95 0.9883\n",
      "Epoch time :  56.935518741607666\n",
      "Epoch  96 0.9869\n",
      "Epoch time :  57.26719379425049\n",
      "Epoch  97 0.988\n",
      "Epoch time :  56.926833629608154\n",
      "Epoch  98 0.9891\n",
      "Epoch time :  55.77579593658447\n",
      "Epoch  99 0.9886\n",
      "Epoch time :  54.76397728919983\n",
      "Epoch  100 0.9897\n",
      "Epoch time :  54.888588428497314\n",
      "Epoch  101 0.9889\n",
      "Epoch time :  54.71372675895691\n",
      "Epoch  102 0.989\n",
      "Epoch time :  54.613712549209595\n",
      "Epoch  103 0.9896\n",
      "Epoch time :  54.81266450881958\n",
      "Epoch  104 0.9901\n",
      "Epoch time :  54.890183448791504\n",
      "Epoch  105 0.9905\n",
      "Epoch time :  54.81577920913696\n",
      "Epoch  106 0.9911\n",
      "Epoch time :  54.7658417224884\n",
      "Epoch  107 0.9901\n",
      "Epoch time :  54.7530198097229\n",
      "Epoch  108 0.9911\n",
      "Epoch time :  54.81600880622864\n",
      "Epoch  109 0.9911\n",
      "Epoch time :  54.783897399902344\n",
      "Epoch  110 0.991\n",
      "Epoch time :  54.9629111289978\n",
      "Epoch  111 0.9916\n",
      "Epoch time :  54.843161821365356\n",
      "Epoch  112 0.9915\n",
      "Epoch time :  54.5156466960907\n",
      "Epoch  113 0.9916\n",
      "Epoch time :  54.798020124435425\n",
      "Epoch  114 0.9906\n",
      "Epoch time :  54.78630566596985\n",
      "Epoch  115 0.9912\n",
      "Epoch time :  54.81604313850403\n",
      "Epoch  116 0.9907\n",
      "Epoch time :  54.90842533111572\n",
      "Epoch  117 0.9911\n",
      "Epoch time :  54.79041361808777\n",
      "Epoch  118 0.9917\n",
      "Epoch time :  54.8258798122406\n",
      "Epoch  119 0.9911\n",
      "Epoch time :  54.97489809989929\n",
      "Epoch  120 0.992\n",
      "Epoch time :  55.04485511779785\n",
      "Epoch  121 0.9922\n",
      "Epoch time :  54.88060426712036\n",
      "Epoch  122 0.9921\n",
      "Epoch time :  54.9330632686615\n",
      "Epoch  123 0.9948\n",
      "Epoch time :  54.84739899635315\n",
      "Epoch  124 0.9958\n",
      "Epoch time :  54.918230295181274\n",
      "Epoch  125 0.9959\n",
      "Epoch time :  54.99177622795105\n",
      "Epoch  126 0.9964\n",
      "Epoch time :  54.79404044151306\n",
      "Epoch  127 0.9961\n",
      "Epoch time :  54.83677053451538\n",
      "Epoch  128 0.9965\n",
      "Epoch time :  54.63370633125305\n",
      "Epoch  129 0.9969\n",
      "Epoch time :  54.880337953567505\n",
      "Epoch  130 0.9968\n",
      "Epoch time :  54.89744424819946\n",
      "Epoch  131 0.9969\n",
      "Epoch time :  54.91292715072632\n",
      "Epoch  132 0.9967\n",
      "Epoch time :  54.92854285240173\n",
      "Epoch  133 0.9972\n",
      "Epoch time :  54.71632170677185\n",
      "Epoch  134 0.9975\n",
      "Epoch time :  54.67706823348999\n",
      "Epoch  135 0.9972\n",
      "Epoch time :  54.84275674819946\n",
      "Epoch  136 0.9972\n",
      "Epoch time :  54.86507439613342\n",
      "Epoch  137 0.9976\n",
      "Epoch time :  54.966684103012085\n",
      "Epoch  138 0.9971\n",
      "Epoch time :  54.80321979522705\n",
      "Epoch  139 0.9972\n",
      "Epoch time :  54.77436137199402\n",
      "Epoch  140 0.9971\n",
      "Epoch time :  54.83390712738037\n",
      "Epoch  141 0.9977\n",
      "Epoch time :  54.74210977554321\n",
      "Epoch  142 0.9972\n",
      "Epoch time :  54.88789963722229\n",
      "Epoch  143 0.9974\n",
      "Epoch time :  54.846226930618286\n",
      "Epoch  144 0.9974\n",
      "Epoch time :  54.70805621147156\n",
      "Epoch  145 0.998\n",
      "Epoch time :  54.86943793296814\n",
      "Epoch  146 0.9977\n",
      "Epoch time :  54.857237100601196\n",
      "Epoch  147 0.9973\n",
      "Epoch time :  54.78595280647278\n",
      "Epoch  148 0.9974\n",
      "Epoch time :  54.83427572250366\n",
      "Epoch  149 0.998\n",
      "Epoch time :  54.691542863845825\n",
      "Epoch  150 0.9977\n",
      "Epoch time :  54.581796169281006\n",
      "Epoch  151 0.9979\n",
      "Epoch time :  54.70814251899719\n",
      "Epoch  152 0.9978\n",
      "Epoch time :  54.6385543346405\n",
      "Epoch  153 0.9977\n",
      "Epoch time :  55.912827014923096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-37d13179ffce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwresnet_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifarWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwresnet_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-36f9be738f71>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(a_net, a_device, dataloader_train_norm, a_epochs, a_batch_size, a_lr)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#             print(labels.cpu())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#             print(prediction2classes(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mepoch_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction2classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mepoch_accuracy\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mepoch_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_weighted_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_weighted_sum\u001b[0;34m(sample_score, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_weighted_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wresnet_4 = CifarWideResNet()\n",
    "train_network(wresnet_4, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution = make_solution(wresnet_4, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = DATA_PATH + 'newest_submission.csv'\n",
    "\n",
    "with open(file_name, 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)\n",
    "        \n",
    "# from google.colab import files\n",
    "# files.download(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
